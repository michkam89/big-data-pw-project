---
warnings: false
---

### Schemat infrastruktury rozwiązania

W celu rozwiązania postawionego problemu analitycznego stworzono infrastrukturę wyłącznie w obrębie chmury AWS, której ogólny schemat przedstawiono na @fig-schema

```{python}
#| include: false


from diagrams import Node, Edge, Cluster, Diagram
from diagrams.aws.compute import EC2
from diagrams.aws.analytics import EMRCluster
from diagrams.aws.storage import S3
from diagrams.aws.devtools import Cloud9

with Diagram("", show=False) as diag:
    
    with Cluster("AWS VPC", direction="LR"):
        c9 = Cloud9("Cloud9") 
        emr = EMRCluster("EMR")

        with Cluster("S3"):
            raw = S3("dane surowe \n (raw-data-beer-and-wine)")
            prepro = S3("dane wstępne \n (preprocessed-data-beer-and-wine)")
            logs = S3("logi \n (emr-logs-beer-and-wine)")

        with Cluster("EMR Cluster"):
            master = EC2("Master")
            nodes =  [ec21 := EC2("Node1"), ec22 := EC2("Node2")]
            master >> Edge(reverse=True) >> nodes
            ec21 >> Edge(reverse=True) >> ec22

        c9 >> Edge(label="(1) dane xml") >> raw 

        raw >> Edge(label="(2) wczytanie danych xml / obróbka") >> emr
        emr >> Edge(label="(3) zapis danych parquet") >> prepro
        emr >> logs
        prepro >> Edge(label="(4) wczytanie danych parquet / analiza") >> emr
        emr >> Edge(style="dashed") >> master

diag
```

![Schemat infrastruktury rozwiązania w chmurze AWS](diagrams_image.png){#fig-schema}

## Ekstrakcja danych surowych {#sec-extraction}

Do etapu ekstrakcji danych wykorzystano usługę `Cloud9`, która zapewnia dostęp do terminala maszyny wirtualnej z systemem linux (platforma `Amazon Linux 2`, typ instancji `t2.micro`). Z użyciem tej usługi dane zostały pobrane ze źródła w binarnym formacie `7z` a następnie pliki zostały wyekstrahowane w formacie `xml` przy pomocy programu `p7zip`. Dane w formacie `xml` zostały następnie skopiowane do serwisu `S3`, gdzie utworzono koszyk danych (ang. _bucket_) o nazwie `raw-data-beer-and-wine`, którego przeznaczeniem jest przetwymywanie danych nieprzetworzonych. 

Powyższe operacje zostały wykonane przy użyciu poniższych poleceń:

```bash
# instalacja programu p7zip
sudo yum install p7zip.x86_64

# pobranie danych
wget https://archive.org/download/stackexchange/beer.stackexchange.com.7z

# ekstrakcja danych do folderu raw-data
7za e  beer.stackexchange.com.7z -oraw-data

# zapis danych do koszyka S3 przy użyciu programu `AWS CLI`
aws s3 cp $(pwd)/raw-data s3://raw-data-beer-and-wine/ --recursive  --include "*.xml"
```

## Przygotowanie danych wstępnych {#sec-prepro}

W celu przygotowania danych do analizy, dane surowe zostały wstępnie przetworzone oraz zapisane w formacie `parquet` w koszyku danych `preprocessed-data-beer-and-wine`, co pozwoliło na wydajniejsze wczytywanie danych podczas uruchomień programu. Podczas etapu wstępnego przetwarzania danych, oprócz zmiany formatu plików, zdefiniowane zostały także schematy danych, które zapewnią, że kolumny wczytanych danych będą posiadały odpowiednie typy oraz, że krytyczne dane nie będą zawierały pustych wartości (@sec-schemas). Dodatkowo kolumny z wartościami tekstowymi, niesłownikowanymi zostały oczyszczone z tagów `html` oraz poddane standardowej procedurze oczyszania tekstu (@sec-text-cleanup).

Powyższe czynności zostały wykonane w notatniku typu Jupiter (ang. _`Jupyter Notebook`_) w serwisie `AWS EMR`. Stworzono klaster `EMR` (wersja 6.8.0) z instalacją `Hadoop` 3.2.1, `Jupyter Hub` 1.4.1 oraz `Spark` 3.3.0. Klaster składał się z 1 instancji typu _master_ oraz 2 instancji typu _core_, każda typu `m4.xlarge`. W celu ograniczenia kosztów jako opcję zakupu wybrano typ `spot` z limitem maksymalnym ceny odpowiadającej typowi `on-demand`. Wielkość dysków `EBS` stworzonych instancji wynosiła 32 GiB dla każdej istancji w klastrze. 

Dostęp do `Jupyter Hub` w utworzonym klastrze jest możliwy poprzez połącznie przez przeglądarkę z środowiskiem graficznym `Jupyter Hub` wykorzystując publiczny adres DNS instancji _master_ i port 9443. Dodatkowo w celu ułatwienia dostępu do `Jupyter Notebook`'ów, utworzony klaster został skonfigurowany na automatycznie ich zapisywanie w dedykowanym koszyku danych w serwisie `S3` (patrz @sec-emr-config)

Polecenia programu AWS CLI odpowiadające za utworzenie klastra, wraz z niezbędnymi dodatkowymi plikami zajdują się w @sec-iac. Wszystkie serwisy AWS na potrzeby tego projektu zostały utworzone w sposób programatyczny przy użyciu programu `AWS CLI` (poza `Cloud9`, który został utworzony z poziomu konsoli zarządzającej).